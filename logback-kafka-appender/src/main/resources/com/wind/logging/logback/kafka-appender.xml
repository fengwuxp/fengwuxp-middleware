<?xml version="1.0" encoding="UTF-8"?>

<!--
Default logback configuration provided for import
-->
<included>
    <springProperty name="KAFKA_SERVERS" scope="context" source="spring.kafka.log.bootstrap-servers"/>
    <springProperty name="KAFKA_TOPIC" scope="context" source="spring.kafka.log.topic"/>
    <springProperty name="KAFKA_RETRIES" scope="context" source="spring.kafka.log.retries" defaultValue="1"/>
    <springProperty name="KAFKA_BATCH_SIZE" scope="context" source="spring.kafka.log.batch-size" defaultValue="16384"/>
    <springProperty name="KAFKA_BUFFER_MEMORY" scope="context" source="spring.kafka.log.buffer-memory" defaultValue="33554432"/>
    <springProperty name="KAFKA_MAX_REQUEST_SIZE" scope="context" source="spring.kafka.log.properties.max-request-size" defaultValue="2097152"/>
    <!--  kafka -->
    <appender name="KAFKA" class="com.wind.logging.logback.kafaka.KafkaAppender">
        <encoder class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">
            <providers class="net.logstash.logback.composite.loggingevent.LoggingEventJsonProviders">
                <pattern>
                    <pattern>
                        {
                        "date": "%d{yyyy-MM-dd HH:mm:ss.SSS}",
                        "A-TraceId": "%X{traceId:-}",
                        "appName": "${APP_NAME}",
                        "env": "${SPRING_PROFILES_ACTIVE}",
                        "requestUrl": "%X{requestUrl:-}",
                        "requestSourceIp": "%X{requestSourceIp:-}",
                        "requestSourceHost": "%X{requestSourceHost:-}",
                        "userAgent": "%X{User-Agent:-}",
                        "podIp": "%X{localhostIpv4:-}",
                        "thread": "%thread",
                        "logger": "%logger",
                        "message": "%msg",
                        "level": "%level",
                        "stack_trace": "%exception"
                        }
                    </pattern>
                </pattern>
            </providers>
        </encoder>
        <topic>${KAFKA_TOPIC}</topic>
        <producerConfig>bootstrap.servers=${KAFKA_SERVERS}</producerConfig>
        <producerConfig>retries=${KAFKA_RETRIES}</producerConfig>
        <producerConfig>batch-size=${KAFKA_BATCH_SIZE}</producerConfig>
        <producerConfig>buffer-memory=${KAFKA_BUFFER_MEMORY}</producerConfig>
        <producerConfig>properties.max.request.size==${KAFKA_MAX_REQUEST_SIZE}</producerConfig>
    </appender>
    <appender name="KAFKA_ASYNC" class="ch.qos.logback.classic.AsyncAppender">
        <!-- if neverBlock is set to true, the async appender discards messages when its internal queue is full -->
        <neverBlock>true</neverBlock>
        <appender-ref ref="KAFKA"/>
    </appender>
</included>